{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used to Debug functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from model import *\n",
    "from dataset import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "# Get gpt-2 tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "vocab_size = tokenizer.n_vocab\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from a test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/the-verdict.txt\", \"r\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "print(len(raw_text), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([126])\n",
      "Labels shape: torch.Size([126])\n"
     ]
    }
   ],
   "source": [
    "dataset = GPTDataset(raw_text, tokenizer, 126, 1) # input phrases of 126 tokens\n",
    "\n",
    "inputs, labels = dataset[0]\n",
    "print(\"Inputs shape:\", inputs.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([32, 126])\n",
      "Labels batch shape: torch.Size([32, 126])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset = dataset,\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "inputs_batch, labels_batch = next(dataiter)\n",
    "\n",
    "print(\"Input batch shape:\", inputs_batch.shape)\n",
    "print(\"Labels batch shape:\", labels_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ModelArgs(\n",
    "    emb_dim = 768,\n",
    "    num_heads = 2,\n",
    "    context_length=1024,\n",
    "    vocab_size=vocab_size,\n",
    "    num_blocks = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 126, 126])\n",
      "Context vector shape: torch.Size([32, 126, 768])\n"
     ]
    }
   ],
   "source": [
    "# apply embedding\n",
    "emb_dim = 768\n",
    "embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "vectors = embedding(inputs_batch)\n",
    "\n",
    "attention = MultiHeadAttention(args)\n",
    "z = attention(vectors)\n",
    "print(\"Context vector shape:\", z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FF block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 126, 768])\n"
     ]
    }
   ],
   "source": [
    "ff = FeedForward(args)\n",
    "out = ff(z)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 126, 768])\n"
     ]
    }
   ],
   "source": [
    "norm = LayerNorm(args)\n",
    "out = norm(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 126, 126])\n",
      "torch.Size([32, 126, 768])\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerBlock(args)\n",
    "out = transformer(vectors)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of parameters of a Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7085568\n"
     ]
    }
   ],
   "source": [
    "print(sum([p.numel() for p in transformer.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GPT Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 126, 126])\n",
      "torch.Size([32, 2, 126, 126])\n",
      "torch.Size([32, 126, 50257])\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(args)\n",
    "out = model(inputs_batch)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of parameters in GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92204113\n"
     ]
    }
   ],
   "source": [
    "print(sum([p.numel() for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 126, 126])\n",
      "torch.Size([32, 2, 126, 126])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9073,  0.0335,  1.4934,  ..., -0.5020, -0.5059, -1.0931],\n",
       "         [-1.3550,  0.8765,  0.8421,  ..., -0.9532,  0.0283, -0.2321],\n",
       "         [-0.3883,  0.3822,  1.3812,  ..., -0.7576,  1.0357, -0.6536],\n",
       "         ...,\n",
       "         [-1.4300,  0.2335,  0.4352,  ..., -0.5809,  0.3527, -2.0563],\n",
       "         [-0.9426,  0.5583,  0.3104,  ..., -0.9327,  0.2543, -0.7374],\n",
       "         [-1.3073,  0.0846,  0.5767,  ..., -0.9223,  0.5519, -0.5645]],\n",
       "\n",
       "        [[-1.1226,  0.1392,  1.9035,  ..., -0.4972, -0.3713, -0.5790],\n",
       "         [-1.1835,  0.5731,  0.9717,  ..., -0.6964,  0.7273, -0.6818],\n",
       "         [-0.7272,  0.7066,  1.3161,  ..., -1.0345,  0.4620, -0.4453],\n",
       "         ...,\n",
       "         [-0.3837,  1.7918, -0.0408,  ..., -0.8322, -0.7472, -1.0639],\n",
       "         [-0.4096,  0.1195,  0.5933,  ..., -1.5029, -0.8600, -1.1141],\n",
       "         [-0.1876, -0.5669,  0.9252,  ..., -0.4962,  0.9002, -0.2192]],\n",
       "\n",
       "        [[-0.3534,  0.9287,  1.0123,  ..., -0.7236, -0.2595, -0.3089],\n",
       "         [-1.2247,  1.2695,  0.4970,  ..., -0.9080, -0.1594, -0.2685],\n",
       "         [-0.7432, -0.1795,  0.5803,  ..., -0.9614,  1.0430, -1.1291],\n",
       "         ...,\n",
       "         [-0.4890,  1.1972, -0.2176,  ..., -0.0509, -0.1140, -0.7907],\n",
       "         [-0.2634,  0.0510,  0.5559,  ..., -0.3534,  0.0611, -1.0158],\n",
       "         [-0.7114,  0.6446,  1.0374,  ...,  0.3428,  0.3200, -1.3773]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.6568,  0.8549,  0.5067,  ..., -0.8991, -0.1338, -0.4808],\n",
       "         [-1.4774,  0.5570,  0.5466,  ..., -0.4203, -0.1416,  0.1458],\n",
       "         [-1.1743, -0.0382,  0.3983,  ...,  0.0219,  1.0926, -1.0024],\n",
       "         ...,\n",
       "         [-0.9355,  1.2502,  0.6020,  ..., -0.5692, -0.2390, -0.9069],\n",
       "         [-1.5306, -0.3681,  0.2299,  ..., -0.6493, -0.4722, -0.4568],\n",
       "         [-0.8714,  0.2446,  0.2070,  ..., -0.7310,  0.7810, -0.8689]],\n",
       "\n",
       "        [[-0.8458,  0.0502,  1.7652,  ..., -1.0146,  0.1428, -0.9199],\n",
       "         [-1.4838,  0.6260,  1.0573,  ..., -1.1484, -0.8671, -0.7022],\n",
       "         [-1.2890,  0.8187,  0.8678,  ..., -1.3744,  0.7134, -1.0997],\n",
       "         ...,\n",
       "         [-0.3537,  1.2118,  0.5185,  ..., -1.1497, -0.3726, -1.0059],\n",
       "         [-0.3298,  0.1721,  0.3310,  ..., -0.8195, -0.1420, -1.5545],\n",
       "         [-0.6534,  0.8832,  0.6222,  ..., -0.7959,  0.0950, -1.0387]],\n",
       "\n",
       "        [[-0.0763,  1.4142,  1.4591,  ..., -0.4796, -0.4780, -0.4958],\n",
       "         [-1.8762,  1.2836,  1.2996,  ..., -0.9507,  0.4059, -0.7206],\n",
       "         [-0.1503,  0.9966,  1.0683,  ..., -0.3238,  0.4513, -0.9671],\n",
       "         ...,\n",
       "         [-0.5010,  0.0402,  0.5360,  ..., -1.2543,  0.2527, -1.2540],\n",
       "         [-1.1225,  0.1847,  0.7058,  ..., -0.8865, -0.3681, -0.8375],\n",
       "         [-0.3520,  0.3109, -0.1019,  ..., -0.4524,  0.1401, -0.3360]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
